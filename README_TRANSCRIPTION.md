# üéôÔ∏è Transcripci√≥n de Audio en Tiempo Real - EddysSipLibrary

Esta documentaci√≥n explica c√≥mo usar las nuevas funcionalidades de **transcripci√≥n de audio en tiempo real** integradas en la librer√≠a SIP.

## üöÄ Caracter√≠sticas de Transcripci√≥n

### ‚úÖ **Funcionalidades Principales**
- üéØ **Interceptaci√≥n directa de audio WebRTC** antes de que llegue al altavoz
- üîÑ **Transcripci√≥n en tiempo real** con resultados parciales y finales
- üéß **M√∫ltiples fuentes de audio**: remoto, local, o ambos
- üåê **Soporte multi-idioma** con detecci√≥n autom√°tica
- üìä **An√°lisis de calidad de audio** en tiempo real
- üíæ **Persistencia autom√°tica** en base de datos Room
- üì§ **Exportaci√≥n** en m√∫ltiples formatos (texto, JSON, SRT, VTT)

### ‚úÖ **Proveedores de Transcripci√≥n**
- ü§ñ **Android Speech Recognition** (incluido)
- ‚òÅÔ∏è **Google Cloud Speech-to-Text** (configuraci√≥n opcional)
- üî∑ **Azure Cognitive Services** (configuraci√≥n opcional)
- üü† **AWS Transcribe** (pr√≥ximamente)

## üì± Configuraci√≥n Inicial

### 1. Permisos Adicionales

Los permisos ya est√°n incluidos en el `AndroidManifest.xml`, pero aseg√∫rate de solicitarlos en runtime:

```kotlin
// Permisos necesarios para transcripci√≥n
val transcriptionPermissions = arrayOf(
    Manifest.permission.RECORD_AUDIO,
    Manifest.permission.CAPTURE_AUDIO_OUTPUT // Para interceptar audio de salida
)

// Solicitar permisos
ActivityCompat.requestPermissions(this, transcriptionPermissions, REQUEST_TRANSCRIPTION_PERMISSIONS)
```

### 2. Inicializaci√≥n en tu Application

```kotlin
class MyApplication : Application() {
    override fun onCreate() {
        super.onCreate()
        
        // Configuraci√≥n de la librer√≠a SIP con transcripci√≥n
        val config = EddysSipLibrary.SipConfig(
            defaultDomain = "tu-dominio.com",
            webSocketUrl = "wss://tu-servidor:puerto/",
            enableLogs = true,
            // Habilitar transcripci√≥n por defecto
            enableTranscription = true
        )
        
        EddysSipLibrary.getInstance().initialize(this, config)
    }
}
```

## üéôÔ∏è Uso B√°sico de Transcripci√≥n

### Configurar Transcripci√≥n

```kotlin
class CallActivity : ComponentActivity() {
    private lateinit var sipLibrary: EddysSipLibrary
    
    override fun onCreate(savedInstanceState: Bundle?) {
        super.onCreate(savedInstanceState)
        
        sipLibrary = EddysSipLibrary.getInstance()
        
        // Configurar transcripci√≥n
        setupTranscription()
    }
    
    private fun setupTranscription() {
        // Configuraci√≥n de transcripci√≥n
        val transcriptionConfig = AudioTranscriptionService.TranscriptionConfig(
            isEnabled = true,
            language = "es-ES", // Espa√±ol
            enablePartialResults = true,
            enablePunctuation = true,
            confidenceThreshold = 0.6f,
            audioSource = AudioTranscriptionService.AudioSource.WEBRTC_REMOTE, // Solo audio remoto
            transcriptionProvider = AudioTranscriptionService.TranscriptionProvider.ANDROID_SPEECH
        )
        
        // Habilitar transcripci√≥n
        sipLibrary.enableAudioTranscription(transcriptionConfig)
        
        // Configurar callbacks
        sipLibrary.setTranscriptionCallbacks(
            onTranscriptionResult = { result ->
                handleTranscriptionResult(result)
            },
            onSessionStateChange = { session ->
                handleSessionStateChange(session)
            },
            onTranscriptionError = { error ->
                showError("Error de transcripci√≥n: $error")
            }
        )
    }
    
    private fun handleTranscriptionResult(result: AudioTranscriptionService.TranscriptionResult) {
        runOnUiThread {
            if (result.isFinal) {
                // Resultado final - mostrar en UI
                addTranscriptionToUI(result.text, result.confidence, result.speakerLabel)
                
                // Guardar en base de datos (autom√°tico)
                Log.d("Transcription", "Final: ${result.text} (${result.confidence})")
            } else {
                // Resultado parcial - mostrar como preview
                showPartialTranscription(result.text)
                Log.d("Transcription", "Partial: ${result.text}")
            }
        }
    }
    
    private fun handleSessionStateChange(session: TranscriptionManager.TranscriptionSession) {
        runOnUiThread {
            if (session.isActive()) {
                showTranscriptionStatus("Transcribiendo...")
            } else {
                showTranscriptionStatus("Transcripci√≥n completada")
                
                // Mostrar estad√≠sticas finales
                val stats = session.statistics
                showSessionStats(stats)
            }
        }
    }
}
```

### Control Durante Llamadas

```kotlin
class InCallViewModel : ViewModel() {
    private val sipLibrary = EddysSipLibrary.getInstance()
    
    // Estados de transcripci√≥n
    val isTranscriptionActive = sipLibrary.getTranscriptionManager()
        ?.isActiveFlow ?: MutableStateFlow(false)
    
    val transcriptionResults = sipLibrary.getTranscriptionManager()
        ?.transcriptionResultFlow ?: MutableStateFlow(null)
    
    val audioLevel = sipLibrary.getTranscriptionManager()
        ?.getAudioLevel() ?: 0f
    
    /**
     * Inicia transcripci√≥n para la llamada actual
     */
    fun startTranscription() {
        val config = AudioTranscriptionService.TranscriptionConfig(
            isEnabled = true,
            language = "es-ES",
            enablePartialResults = true,
            audioSource = AudioTranscriptionService.AudioSource.WEBRTC_REMOTE
        )
        
        sipLibrary.startTranscriptionForCurrentCall(config)
    }
    
    /**
     * Detiene transcripci√≥n
     */
    fun stopTranscription() {
        sipLibrary.stopTranscriptionForCurrentCall()
    }
    
    /**
     * Cambia idioma de transcripci√≥n
     */
    fun changeTranscriptionLanguage(language: String) {
        sipLibrary.setTranscriptionLanguage(language)
    }
    
    /**
     * Cambia fuente de audio
     */
    fun changeAudioSource(source: AudioTranscriptionService.AudioSource) {
        sipLibrary.setTranscriptionAudioSource(source)
    }
    
    /**
     * Exporta transcripci√≥n actual
     */
    fun exportCurrentTranscription(format: TranscriptionManager.ExportFormat): String? {
        val session = sipLibrary.getCurrentTranscriptionSession()
        return if (session != null) {
            sipLibrary.exportTranscriptionSession(session.id, format)
        } else {
            null
        }
    }
}
```

## üé® UI de Transcripci√≥n con Compose

### Pantalla de Transcripci√≥n en Tiempo Real

```kotlin
@Composable
fun TranscriptionScreen(viewModel: InCallViewModel) {
    val isTranscriptionActive by viewModel.isTranscriptionActive.collectAsState()
    val transcriptionResult by viewModel.transcriptionResults.collectAsState()
    val audioLevel = viewModel.audioLevel
    
    Column(
        modifier = Modifier
            .fillMaxSize()
            .padding(16.dp)
    ) {
        // Header con controles
        TranscriptionHeader(
            isActive = isTranscriptionActive,
            audioLevel = audioLevel,
            onToggleTranscription = {
                if (isTranscriptionActive) {
                    viewModel.stopTranscription()
                } else {
                    viewModel.startTranscription()
                }
            },
            onChangeLanguage = { language ->
                viewModel.changeTranscriptionLanguage(language)
            }
        )
        
        Spacer(modifier = Modifier.height(16.dp))
        
        // √Årea de transcripci√≥n
        TranscriptionContent(
            result = transcriptionResult,
            isActive = isTranscriptionActive
        )
        
        Spacer(modifier = Modifier.height(16.dp))
        
        // Controles adicionales
        TranscriptionControls(
            onChangeAudioSource = { source ->
                viewModel.changeAudioSource(source)
            },
            onExport = { format ->
                val exported = viewModel.exportCurrentTranscription(format)
                if (exported != null) {
                    // Compartir o guardar archivo
                    shareTranscription(exported, format)
                }
            }
        )
    }
}

@Composable
fun TranscriptionHeader(
    isActive: Boolean,
    audioLevel: Float,
    onToggleTranscription: () -> Unit,
    onChangeLanguage: (String) -> Unit
) {
    Card(
        modifier = Modifier.fillMaxWidth(),
        elevation = 4.dp
    ) {
        Column(
            modifier = Modifier.padding(16.dp)
        ) {
            Row(
                modifier = Modifier.fillMaxWidth(),
                horizontalArrangement = Arrangement.SpaceBetween,
                verticalAlignment = Alignment.CenterVertically
            ) {
                Text(
                    text = "Transcripci√≥n de Audio",
                    style = MaterialTheme.typography.h6
                )
                
                Switch(
                    checked = isActive,
                    onCheckedChange = { onToggleTranscription() }
                )
            }
            
            Spacer(modifier = Modifier.height(8.dp))
            
            // Indicador de nivel de audio
            AudioLevelIndicator(
                level = audioLevel,
                isActive = isActive
            )
            
            Spacer(modifier = Modifier.height(8.dp))
            
            // Selector de idioma
            LanguageSelector(
                currentLanguage = "es-ES",
                onLanguageSelected = onChangeLanguage
            )
        }
    }
}

@Composable
fun AudioLevelIndicator(
    level: Float,
    isActive: Boolean
) {
    Row(
        verticalAlignment = Alignment.CenterVertically
    ) {
        Icon(
            imageVector = if (isActive) Icons.Default.Mic else Icons.Default.MicOff,
            contentDescription = null,
            tint = if (isActive) MaterialTheme.colors.primary else MaterialTheme.colors.onSurface.copy(alpha = 0.5f)
        )
        
        Spacer(modifier = Modifier.width(8.dp))
        
        LinearProgressIndicator(
            progress = level,
            modifier = Modifier
                .weight(1f)
                .height(8.dp)
                .clip(RoundedCornerShape(4.dp)),
            color = when {
                level > 0.8f -> Color.Red
                level > 0.5f -> Color.Orange
                level > 0.2f -> Color.Green
                else -> MaterialTheme.colors.primary.copy(alpha = 0.3f)
            }
        )
        
        Spacer(modifier = Modifier.width(8.dp))
        
        Text(
            text = "${(level * 100).toInt()}%",
            style = MaterialTheme.typography.caption
        )
    }
}

@Composable
fun LanguageSelector(
    currentLanguage: String,
    onLanguageSelected: (String) -> Unit
) {
    var expanded by remember { mutableStateOf(false) }
    
    val languages = mapOf(
        "es-ES" to "Espa√±ol",
        "en-US" to "English",
        "fr-FR" to "Fran√ßais",
        "de-DE" to "Deutsch",
        "it-IT" to "Italiano",
        "pt-BR" to "Portugu√™s"
    )
    
    Box {
        OutlinedButton(
            onClick = { expanded = true },
            modifier = Modifier.fillMaxWidth()
        ) {
            Text("Idioma: ${languages[currentLanguage] ?: currentLanguage}")
            Icon(Icons.Default.ArrowDropDown, contentDescription = null)
        }
        
        DropdownMenu(
            expanded = expanded,
            onDismissRequest = { expanded = false }
        ) {
            languages.forEach { (code, name) ->
                DropdownMenuItem(
                    onClick = {
                        onLanguageSelected(code)
                        expanded = false
                    }
                ) {
                    Text(name)
                }
            }
        }
    }
}

@Composable
fun TranscriptionContent(
    result: AudioTranscriptionService.TranscriptionResult?,
    isActive: Boolean
) {
    Card(
        modifier = Modifier
            .fillMaxWidth()
            .height(300.dp),
        elevation = 2.dp
    ) {
        if (isActive) {
            LazyColumn(
                modifier = Modifier
                    .fillMaxSize()
                    .padding(16.dp),
                reverseLayout = true // Mostrar lo m√°s reciente arriba
            ) {
                if (result != null) {
                    item {
                        TranscriptionItem(
                            result = result,
                            isLatest = true
                        )
                    }
                }
                
                // Aqu√≠ se mostrar√≠an resultados anteriores del historial
            }
        } else {
            Box(
                modifier = Modifier.fillMaxSize(),
                contentAlignment = Alignment.Center
            ) {
                Column(
                    horizontalAlignment = Alignment.CenterHorizontally
                ) {
                    Icon(
                        Icons.Default.MicOff,
                        contentDescription = null,
                        modifier = Modifier.size(48.dp),
                        tint = MaterialTheme.colors.onSurface.copy(alpha = 0.5f)
                    )
                    Spacer(modifier = Modifier.height(8.dp))
                    Text(
                        text = "Transcripci√≥n desactivada",
                        style = MaterialTheme.typography.body1,
                        color = MaterialTheme.colors.onSurface.copy(alpha = 0.7f)
                    )
                }
            }
        }
    }
}

@Composable
fun TranscriptionItem(
    result: AudioTranscriptionService.TranscriptionResult,
    isLatest: Boolean
) {
    Card(
        modifier = Modifier
            .fillMaxWidth()
            .padding(vertical = 4.dp),
        backgroundColor = if (isLatest && !result.isFinal) {
            MaterialTheme.colors.primary.copy(alpha = 0.1f)
        } else {
            MaterialTheme.colors.surface
        },
        border = if (isLatest && !result.isFinal) {
            BorderStroke(1.dp, MaterialTheme.colors.primary.copy(alpha = 0.3f))
        } else null
    ) {
        Column(
            modifier = Modifier.padding(12.dp)
        ) {
            Row(
                modifier = Modifier.fillMaxWidth(),
                horizontalArrangement = Arrangement.SpaceBetween,
                verticalAlignment = Alignment.CenterVertically
            ) {
                // Indicador de speaker
                Row(verticalAlignment = Alignment.CenterVertically) {
                    Icon(
                        imageVector = if (result.speakerLabel == "remote") Icons.Default.Person else Icons.Default.PersonOutline,
                        contentDescription = null,
                        modifier = Modifier.size(16.dp),
                        tint = if (result.speakerLabel == "remote") MaterialTheme.colors.primary else MaterialTheme.colors.secondary
                    )
                    Spacer(modifier = Modifier.width(4.dp))
                    Text(
                        text = if (result.speakerLabel == "remote") "Remoto" else "Local",
                        style = MaterialTheme.typography.caption,
                        color = MaterialTheme.colors.onSurface.copy(alpha = 0.7f)
                    )
                }
                
                // Timestamp y confianza
                Row(verticalAlignment = Alignment.CenterVertically) {
                    if (!result.isFinal) {
                        Icon(
                            Icons.Default.Edit,
                            contentDescription = "Parcial",
                            modifier = Modifier.size(12.dp),
                            tint = MaterialTheme.colors.primary
                        )
                        Spacer(modifier = Modifier.width(4.dp))
                    }
                    
                    Text(
                        text = "${(result.confidence * 100).toInt()}%",
                        style = MaterialTheme.typography.caption,
                        color = when {
                            result.confidence > 0.8f -> Color.Green
                            result.confidence > 0.5f -> Color.Orange
                            else -> Color.Red
                        }
                    )
                    
                    Spacer(modifier = Modifier.width(8.dp))
                    
                    Text(
                        text = SimpleDateFormat("HH:mm:ss", Locale.getDefault()).format(Date(result.timestamp)),
                        style = MaterialTheme.typography.caption,
                        color = MaterialTheme.colors.onSurface.copy(alpha = 0.5f)
                    )
                }
            }
            
            Spacer(modifier = Modifier.height(8.dp))
            
            // Texto transcrito
            Text(
                text = result.text,
                style = MaterialTheme.typography.body1,
                color = if (result.isFinal) {
                    MaterialTheme.colors.onSurface
                } else {
                    MaterialTheme.colors.onSurface.copy(alpha = 0.7f)
                }
            )
        }
    }
}

@Composable
fun TranscriptionControls(
    onChangeAudioSource: (AudioTranscriptionService.AudioSource) -> Unit,
    onExport: (TranscriptionManager.ExportFormat) -> Unit
) {
    Card(
        modifier = Modifier.fillMaxWidth(),
        elevation = 2.dp
    ) {
        Column(
            modifier = Modifier.padding(16.dp)
        ) {
            Text(
                text = "Controles de Transcripci√≥n",
                style = MaterialTheme.typography.subtitle1,
                modifier = Modifier.padding(bottom = 12.dp)
            )
            
            // Selector de fuente de audio
            AudioSourceSelector(
                onSourceSelected = onChangeAudioSource
            )
            
            Spacer(modifier = Modifier.height(12.dp))
            
            // Botones de exportaci√≥n
            Row(
                modifier = Modifier.fillMaxWidth(),
                horizontalArrangement = Arrangement.SpaceEvenly
            ) {
                ExportButton("Texto", TranscriptionManager.ExportFormat.TEXT, onExport)
                ExportButton("JSON", TranscriptionManager.ExportFormat.JSON, onExport)
                ExportButton("SRT", TranscriptionManager.ExportFormat.SRT, onExport)
                ExportButton("VTT", TranscriptionManager.ExportFormat.VTT, onExport)
            }
        }
    }
}

@Composable
fun AudioSourceSelector(
    onSourceSelected: (AudioTranscriptionService.AudioSource) -> Unit
) {
    var selectedSource by remember { mutableStateOf(AudioTranscriptionService.AudioSource.WEBRTC_REMOTE) }
    
    Column {
        Text(
            text = "Fuente de Audio:",
            style = MaterialTheme.typography.body2,
            modifier = Modifier.padding(bottom = 8.dp)
        )
        
        Row(
            modifier = Modifier.fillMaxWidth(),
            horizontalArrangement = Arrangement.SpaceEvenly
        ) {
            AudioSourceOption(
                text = "Remoto",
                source = AudioTranscriptionService.AudioSource.WEBRTC_REMOTE,
                isSelected = selectedSource == AudioTranscriptionService.AudioSource.WEBRTC_REMOTE,
                onSelected = {
                    selectedSource = it
                    onSourceSelected(it)
                }
            )
            
            AudioSourceOption(
                text = "Local",
                source = AudioTranscriptionService.AudioSource.WEBRTC_LOCAL,
                isSelected = selectedSource == AudioTranscriptionService.AudioSource.WEBRTC_LOCAL,
                onSelected = {
                    selectedSource = it
                    onSourceSelected(it)
                }
            )
            
            AudioSourceOption(
                text = "Ambos",
                source = AudioTranscriptionService.AudioSource.WEBRTC_BOTH,
                isSelected = selectedSource == AudioTranscriptionService.AudioSource.WEBRTC_BOTH,
                onSelected = {
                    selectedSource = it
                    onSourceSelected(it)
                }
            )
        }
    }
}

@Composable
fun AudioSourceOption(
    text: String,
    source: AudioTranscriptionService.AudioSource,
    isSelected: Boolean,
    onSelected: (AudioTranscriptionService.AudioSource) -> Unit
) {
    FilterChip(
        selected = isSelected,
        onClick = { onSelected(source) },
        label = { Text(text) },
        selectedIcon = {
            Icon(
                Icons.Default.Check,
                contentDescription = null,
                modifier = Modifier.size(16.dp)
            )
        }
    )
}

@Composable
fun ExportButton(
    text: String,
    format: TranscriptionManager.ExportFormat,
    onExport: (TranscriptionManager.ExportFormat) -> Unit
) {
    OutlinedButton(
        onClick = { onExport(format) },
        modifier = Modifier.padding(horizontal = 4.dp)
    ) {
        Text(text)
    }
}
```

## üìä Historial y Estad√≠sticas

### Pantalla de Historial de Transcripciones

```kotlin
@Composable
fun TranscriptionHistoryScreen(databaseManager: DatabaseManager) {
    var searchQuery by remember { mutableStateOf("") }
    
    val transcriptionSessions by databaseManager.getTranscriptionSessions()
        .collectAsState(initial = emptyList())
    
    val searchResults by if (searchQuery.isBlank()) {
        flowOf(emptyList<TranscriptionEntity>())
    } else {
        databaseManager.searchTranscriptions(searchQuery)
    }.collectAsState(initial = emptyList())
    
    Column {
        // Barra de b√∫squeda
        OutlinedTextField(
            value = searchQuery,
            onValueChange = { searchQuery = it },
            label = { Text("Buscar en transcripciones...") },
            leadingIcon = { Icon(Icons.Default.Search, contentDescription = null) },
            modifier = Modifier
                .fillMaxWidth()
                .padding(16.dp)
        )
        
        if (searchQuery.isBlank()) {
            // Mostrar sesiones
            LazyColumn {
                items(transcriptionSessions) { session ->
                    TranscriptionSessionItem(
                        session = session,
                        onClick = { 
                            // Navegar a detalles de sesi√≥n
                        }
                    )
                }
            }
        } else {
            // Mostrar resultados de b√∫squeda
            LazyColumn {
                items(searchResults) { transcription ->
                    TranscriptionSearchResultItem(
                        transcription = transcription,
                        searchQuery = searchQuery
                    )
                }
            }
        }
    }
}

@Composable
fun TranscriptionSessionItem(
    session: TranscriptionSessionEntity,
    onClick: () -> Unit
) {
    Card(
        modifier = Modifier
            .fillMaxWidth()
            .padding(horizontal = 16.dp, vertical = 4.dp)
            .clickable { onClick() }
    ) {
        Column(
            modifier = Modifier.padding(16.dp)
        ) {
            Row(
                modifier = Modifier.fillMaxWidth(),
                horizontalArrangement = Arrangement.SpaceBetween
            ) {
                Text(
                    text = "Sesi√≥n ${session.id.take(8)}",
                    style = MaterialTheme.typography.subtitle1
                )
                
                Text(
                    text = session.getFormattedDuration(),
                    style = MaterialTheme.typography.body2,
                    color = MaterialTheme.colors.primary
                )
            }
            
            Spacer(modifier = Modifier.height(4.dp))
            
            Text(
                text = SimpleDateFormat("dd/MM/yyyy HH:mm", Locale.getDefault()).format(Date(session.startTime)),
                style = MaterialTheme.typography.body2,
                color = MaterialTheme.colors.onSurface.copy(alpha = 0.6f)
            )
            
            Spacer(modifier = Modifier.height(8.dp))
            
            // Estad√≠sticas
            Row(
                modifier = Modifier.fillMaxWidth(),
                horizontalArrangement = Arrangement.SpaceEvenly
            ) {
                StatChip("${session.totalWords} palabras")
                StatChip("${(session.averageConfidence * 100).toInt()}% confianza")
                StatChip("${session.language}")
            }
        }
    }
}

@Composable
fun StatChip(text: String) {
    Surface(
        color = MaterialTheme.colors.primary.copy(alpha = 0.1f),
        shape = RoundedCornerShape(12.dp)
    ) {
        Text(
            text = text,
            modifier = Modifier.padding(horizontal = 8.dp, vertical = 4.dp),
            style = MaterialTheme.typography.caption,
            color = MaterialTheme.colors.primary
        )
    }
}
```

## üîß Configuraci√≥n Avanzada

### Configuraci√≥n de Proveedores en la Nube

```kotlin
class TranscriptionConfigManager {
    
    /**
     * Configura Google Cloud Speech-to-Text
     */
    fun setupGoogleCloudSpeech(apiKey: String) {
        val config = AudioTranscriptionService.TranscriptionConfig(
            isEnabled = true,
            language = "es-ES",
            transcriptionProvider = AudioTranscriptionService.TranscriptionProvider.GOOGLE_CLOUD,
            enablePartialResults = true,
            confidenceThreshold = 0.7f
        )
        
        // Configurar proveedor
        val provider = TranscriptionProviderFactory.createProvider(
            provider = AudioTranscriptionService.TranscriptionProvider.GOOGLE_CLOUD,
            apiKey = apiKey
        )
        
        if (provider != null) {
            sipLibrary.enableAudioTranscription(config)
        }
    }
    
    /**
     * Configura Azure Cognitive Services
     */
    fun setupAzureSpeech(subscriptionKey: String, region: String) {
        val config = AudioTranscriptionService.TranscriptionConfig(
            isEnabled = true,
            language = "es-ES",
            transcriptionProvider = AudioTranscriptionService.TranscriptionProvider.AZURE_COGNITIVE,
            enablePartialResults = true,
            confidenceThreshold = 0.6f
        )
        
        val provider = TranscriptionProviderFactory.createProvider(
            provider = AudioTranscriptionService.TranscriptionProvider.AZURE_COGNITIVE,
            apiKey = subscriptionKey,
            region = region
        )
        
        if (provider != null) {
            sipLibrary.enableAudioTranscription(config)
        }
    }
}
```

### Configuraci√≥n Personalizada de Audio

```kotlin
class CustomAudioTranscriptionSetup {
    
    fun setupAdvancedTranscription() {
        val config = AudioTranscriptionService.TranscriptionConfig(
            isEnabled = true,
            language = "es-ES",
            enablePartialResults = true,
            enableProfanityFilter = false,
            enablePunctuation = true,
            confidenceThreshold = 0.5f,
            maxSilenceDurationMs = 2000L, // 2 segundos de silencio m√°ximo
            audioSource = AudioTranscriptionService.AudioSource.WEBRTC_BOTH, // Transcribir ambos audios
            transcriptionProvider = AudioTranscriptionService.TranscriptionProvider.ANDROID_SPEECH
        )
        
        sipLibrary.enableAudioTranscription(config)
        
        // Configurar callbacks avanzados
        sipLibrary.setTranscriptionCallbacks(
            onTranscriptionResult = { result ->
                handleAdvancedTranscriptionResult(result)
            },
            onSessionStateChange = { session ->
                handleAdvancedSessionChange(session)
            },
            onTranscriptionError = { error ->
                handleTranscriptionError(error)
            }
        )
    }
    
    private fun handleAdvancedTranscriptionResult(result: AudioTranscriptionService.TranscriptionResult) {
        // An√°lisis avanzado del resultado
        when {
            result.confidence > 0.9f -> {
                // Alta confianza - procesar inmediatamente
                processHighConfidenceResult(result)
            }
            result.confidence > 0.6f -> {
                // Confianza media - validar con contexto
                validateMediumConfidenceResult(result)
            }
            else -> {
                // Baja confianza - marcar para revisi√≥n
                flagLowConfidenceResult(result)
            }
        }
        
        // Detectar palabras clave
        detectKeywords(result.text)
        
        // An√°lisis de sentimiento b√°sico
        analyzeSentiment(result.text)
    }
    
    private fun processHighConfidenceResult(result: AudioTranscriptionService.TranscriptionResult) {
        // Procesar resultado de alta confianza
        Log.d("Transcription", "High confidence result: ${result.text}")
    }
    
    private fun validateMediumConfidenceResult(result: AudioTranscriptionService.TranscriptionResult) {
        // Validar resultado de confianza media
        Log.d("Transcription", "Medium confidence result: ${result.text}")
    }
    
    private fun flagLowConfidenceResult(result: AudioTranscriptionService.TranscriptionResult) {
        // Marcar resultado de baja confianza para revisi√≥n
        Log.w("Transcription", "Low confidence result: ${result.text}")
    }
    
    private fun detectKeywords(text: String) {
        val keywords = listOf("urgente", "importante", "problema", "error", "ayuda")
        val foundKeywords = keywords.filter { text.contains(it, ignoreCase = true) }
        
        if (foundKeywords.isNotEmpty()) {
            Log.i("Transcription", "Keywords detected: $foundKeywords")
            // Notificar o tomar acci√≥n espec√≠fica
        }
    }
    
    private fun analyzeSentiment(text: String) {
        // An√°lisis b√°sico de sentimiento
        val positiveWords = listOf("bien", "bueno", "excelente", "perfecto", "gracias")
        val negativeWords = listOf("mal", "problema", "error", "molesto", "terrible")
        
        val positiveCount = positiveWords.count { text.contains(it, ignoreCase = true) }
        val negativeCount = negativeWords.count { text.contains(it, ignoreCase = true) }
        
        val sentiment = when {
            positiveCount > negativeCount -> "Positivo"
            negativeCount > positiveCount -> "Negativo"
            else -> "Neutral"
        }
        
        Log.d("Transcription", "Sentiment analysis: $sentiment")
    }
}
```

## üìà Monitoreo y An√°lisis

### Dashboard de Transcripci√≥n

```kotlin
@Composable
fun TranscriptionDashboard(databaseManager: DatabaseManager) {
    var statistics by remember { mutableStateOf<AudioTranscriptionService.TranscriptionStatistics?>(null) }
    var audioQuality by remember { mutableStateOf<WebRtcAudioInterceptor.AudioQuality?>(null) }
    
    LaunchedEffect(Unit) {
        // Obtener estad√≠sticas
        statistics = sipLibrary.getTranscriptionStatistics()
        audioQuality = sipLibrary.getCurrentAudioQuality()
    }
    
    LazyColumn(
        modifier = Modifier.padding(16.dp),
        verticalArrangement = Arrangement.spacedBy(16.dp)
    ) {
        item {
            Text(
                text = "Dashboard de Transcripci√≥n",
                style = MaterialTheme.typography.h5
            )
        }
        
        statistics?.let { stats ->
            item {
                TranscriptionStatsCard(stats)
            }
        }
        
        audioQuality?.let { quality ->
            item {
                AudioQualityCard(quality)
            }
        }
        
        item {
            RealtimeTranscriptionCard()
        }
    }
}

@Composable
fun TranscriptionStatsCard(stats: AudioTranscriptionService.TranscriptionStatistics) {
    Card(
        modifier = Modifier.fillMaxWidth(),
        elevation = 4.dp
    ) {
        Column(
            modifier = Modifier.padding(16.dp)
        ) {
            Text(
                text = "Estad√≠sticas de Transcripci√≥n",
                style = MaterialTheme.typography.h6,
                modifier = Modifier.padding(bottom = 12.dp)
            )
            
            Row(
                modifier = Modifier.fillMaxWidth(),
                horizontalArrangement = Arrangement.SpaceEvenly
            ) {
                StatItem("Total", stats.totalTranscriptions.toString())
                StatItem("Finales", stats.finalTranscriptions.toString())
                StatItem("Parciales", stats.partialTranscriptions.toString())
            }
            
            Spacer(modifier = Modifier.height(12.dp))
            
            Row(
                modifier = Modifier.fillMaxWidth(),
                horizontalArrangement = Arrangement.SpaceEvenly
            ) {
                StatItem("Confianza Promedio", "${(stats.averageConfidence * 100).toInt()}%")
                StatItem("Duraci√≥n Total", "${stats.totalDuration / 1000}s")
                StatItem("Idiomas", stats.languagesUsed.size.toString())
            }
        }
    }
}

@Composable
fun AudioQualityCard(quality: WebRtcAudioInterceptor.AudioQuality) {
    Card(
        modifier = Modifier.fillMaxWidth(),
        elevation = 4.dp
    ) {
        Column(
            modifier = Modifier.padding(16.dp)
        ) {
            Text(
                text = "Calidad de Audio",
                style = MaterialTheme.typography.h6,
                modifier = Modifier.padding(bottom = 12.dp)
            )
            
            // Nivel promedio
            QualityIndicator(
                label = "Nivel Promedio",
                value = quality.averageLevel,
                maxValue = 1f,
                color = MaterialTheme.colors.primary
            )
            
            Spacer(modifier = Modifier.height(8.dp))
            
            // SNR
            QualityIndicator(
                label = "SNR",
                value = quality.signalToNoiseRatio,
                maxValue = 60f,
                color = Color.Green,
                unit = "dB"
            )
            
            Spacer(modifier = Modifier.height(8.dp))
            
            // Indicadores de problemas
            Row(
                modifier = Modifier.fillMaxWidth(),
                horizontalArrangement = Arrangement.SpaceEvenly
            ) {
                ProblemIndicator(
                    label = "Clipping",
                    hasIssue = quality.clippingDetected,
                    icon = Icons.Default.Warning
                )
                
                ProblemIndicator(
                    label = "Silencio",
                    hasIssue = quality.silenceDetected,
                    icon = Icons.Default.VolumeOff
                )
            }
        }
    }
}

@Composable
fun QualityIndicator(
    label: String,
    value: Float,
    maxValue: Float,
    color: Color,
    unit: String = ""
) {
    Column {
        Row(
            modifier = Modifier.fillMaxWidth(),
            horizontalArrangement = Arrangement.SpaceBetween
        ) {
            Text(
                text = label,
                style = MaterialTheme.typography.body2
            )
            Text(
                text = "${value.toInt()}$unit",
                style = MaterialTheme.typography.body2,
                fontWeight = FontWeight.Bold
            )
        }
        
        LinearProgressIndicator(
            progress = (value / maxValue).coerceIn(0f, 1f),
            modifier = Modifier
                .fillMaxWidth()
                .height(8.dp)
                .clip(RoundedCornerShape(4.dp)),
            color = color
        )
    }
}

@Composable
fun ProblemIndicator(
    label: String,
    hasIssue: Boolean,
    icon: ImageVector
) {
    Row(
        verticalAlignment = Alignment.CenterVertically
    ) {
        Icon(
            imageVector = icon,
            contentDescription = null,
            modifier = Modifier.size(16.dp),
            tint = if (hasIssue) Color.Red else Color.Green
        )
        Spacer(modifier = Modifier.width(4.dp))
        Text(
            text = label,
            style = MaterialTheme.typography.caption,
            color = if (hasIssue) Color.Red else Color.Green
        )
    }
}
```

## üîß Integraci√≥n Autom√°tica

### Auto-inicio de Transcripci√≥n

```kotlin
class AutoTranscriptionManager(
    private val sipLibrary: EddysSipLibrary,
    private val databaseManager: DatabaseManager
) {
    
    fun setupAutoTranscription() {
        sipLibrary.addSipEventListener(object : EddysSipLibrary.SipEventListener {
            override fun onCallStateChanged(stateInfo: CallStateInfo) {
                when (stateInfo.state) {
                    CallState.STREAMS_RUNNING -> {
                        // Llamada conectada - iniciar transcripci√≥n autom√°ticamente
                        startAutoTranscription(stateInfo.callId)
                    }
                    
                    CallState.ENDED -> {
                        // Llamada terminada - detener transcripci√≥n
                        stopAutoTranscription()
                    }
                }
            }
        })
    }
    
    private fun startAutoTranscription(callId: String) {
        val config = AudioTranscriptionService.TranscriptionConfig(
            isEnabled = true,
            language = getPreferredLanguage(),
            enablePartialResults = true,
            audioSource = AudioTranscriptionService.AudioSource.WEBRTC_REMOTE,
            confidenceThreshold = 0.5f
        )
        
        sipLibrary.startTranscriptionForCurrentCall(config)
        
        Log.d("AutoTranscription", "Auto-transcription started for call: $callId")
    }
    
    private fun stopAutoTranscription() {
        sipLibrary.stopTranscriptionForCurrentCall()
        Log.d("AutoTranscription", "Auto-transcription stopped")
    }
    
    private fun get PreferredLanguage(): String {
        // Obtener idioma preferido del usuario o del sistema
        return Locale.getDefault().toLanguageTag()
    }
}
```

## üö® Mejores Pr√°cticas

### 1. **Gesti√≥n de Recursos**

```kotlin
class TranscriptionResourceManager {
    
    fun optimizeForBattery() {
        // Configuraci√≥n optimizada para bater√≠a
        val config = AudioTranscriptionService.TranscriptionConfig(
            isEnabled = true,
            enablePartialResults = false, // Menos procesamiento
            confidenceThreshold = 0.7f, // Mayor umbral
            maxSilenceDurationMs = 5000L // M√°s tolerancia al silencio
        )
        
        sipLibrary.enableAudioTranscription(config)
    }
    
    fun optimizeForAccuracy() {
        // Configuraci√≥n optimizada para precisi√≥n
        val config = AudioTranscriptionService.TranscriptionConfig(
            isEnabled = true,
            enablePartialResults = true,
            confidenceThreshold = 0.3f, // Menor umbral
            maxSilenceDurationMs = 1000L, // Menos tolerancia al silencio
            transcriptionProvider = AudioTranscriptionService.TranscriptionProvider.GOOGLE_CLOUD
        )
        
        sipLibrary.enableAudioTranscription(config)
    }
}
```

### 2. **Manejo de Errores**

```kotlin
class TranscriptionErrorHandler {
    
    fun setupErrorHandling() {
        sipLibrary.setTranscriptionCallbacks(
            onTranscriptionError = { error ->
                when {
                    error.contains("network", ignoreCase = true) -> {
                        // Error de red - cambiar a proveedor local
                        fallbackToLocalProvider()
                    }
                    error.contains("permission", ignoreCase = true) -> {
                        // Error de permisos - solicitar permisos
                        requestTranscriptionPermissions()
                    }
                    error.contains("busy", ignoreCase = true) -> {
                        // Servicio ocupado - reintentar despu√©s
                        retryTranscriptionAfterDelay()
                    }
                    else -> {
                        // Error gen√©rico - log y notificar
                        logTranscriptionError(error)
                    }
                }
            }
        )
    }
    
    private fun fallbackToLocalProvider() {
        val fallbackConfig = AudioTranscriptionService.TranscriptionConfig(
            transcriptionProvider = AudioTranscriptionService.TranscriptionProvider.ANDROID_SPEECH
        )
        sipLibrary.enableAudioTranscription(fallbackConfig)
    }
    
    private fun requestTranscriptionPermissions() {
        // Solicitar permisos necesarios
    }
    
    private fun retryTranscriptionAfterDelay() {
        // Reintentar despu√©s de un delay
        Handler(Looper.getMainLooper()).postDelayed({
            sipLibrary.startTranscriptionForCurrentCall()
        }, 3000)
    }
    
    private fun logTranscriptionError(error: String) {
        Log.e("TranscriptionError", error)
        // Enviar a analytics o crash reporting
    }
}
```

## üìÑ Exportaci√≥n y Compartir

### Exportar Transcripciones

```kotlin
class TranscriptionExporter {
    
    fun exportAndShare(
        sessionId: String,
        format: TranscriptionManager.ExportFormat,
        context: Context
    ) {
        val exported = sipLibrary.exportTranscriptionSession(sessionId, format)
        
        if (exported != null) {
            when (format) {
                TranscriptionManager.ExportFormat.TEXT -> shareAsText(exported, context)
                TranscriptionManager.ExportFormat.JSON -> saveAsFile(exported, "transcription.json", context)
                TranscriptionManager.ExportFormat.SRT -> saveAsFile(exported, "transcription.srt", context)
                TranscriptionManager.ExportFormat.VTT -> saveAsFile(exported, "transcription.vtt", context)
            }
        }
    }
    
    private fun shareAsText(content: String, context: Context) {
        val shareIntent = Intent().apply {
            action = Intent.ACTION_SEND
            type = "text/plain"
            putExtra(Intent.EXTRA_TEXT, content)
            putExtra(Intent.EXTRA_SUBJECT, "Transcripci√≥n de Llamada")
        }
        
        context.startActivity(Intent.createChooser(shareIntent, "Compartir transcripci√≥n"))
    }
    
    private fun saveAsFile(content: String, filename: String, context: Context) {
        try {
            val file = File(context.getExternalFilesDir(Environment.DIRECTORY_DOCUMENTS), filename)
            file.writeText(content)
            
            // Notificar al usuario
            Toast.makeText(context, "Archivo guardado: ${file.absolutePath}", Toast.LENGTH_LONG).show()
            
        } catch (e: Exception) {
            Log.e("TranscriptionExporter", "Error saving file: ${e.message}")
        }
    }
}
```

## üéØ Casos de Uso Avanzados

### 1. **Transcripci√≥n Biling√ºe**

```kotlin
fun setupBilingualTranscription() {
    // Detectar idioma autom√°ticamente y cambiar configuraci√≥n
    sipLibrary.setTranscriptionCallbacks(
        onTranscriptionResult = { result ->
            val detectedLanguage = detectLanguage(result.text)
            if (detectedLanguage != result.language) {
                // Cambiar idioma de transcripci√≥n
                sipLibrary.setTranscriptionLanguage(detectedLanguage)
            }
        }
    )
}

private fun detectLanguage(text: String): String {
    // Implementaci√≥n b√°sica de detecci√≥n de idioma
    val spanishWords = listOf("el", "la", "de", "que", "y", "en", "un", "es", "se", "no")
    val englishWords = listOf("the", "of", "and", "to", "a", "in", "is", "it", "you", "that")
    
    val words = text.lowercase().split("\\s+".toRegex())
    val spanishCount = words.count { it in spanishWords }
    val englishCount = words.count { it in englishWords }
    
    return if (spanishCount > englishCount) "es-ES" else "en-US"
}
```

### 2. **An√°lisis de Conversaci√≥n**

```kotlin
class ConversationAnalyzer {
    
    fun analyzeConversation(session: TranscriptionManager.TranscriptionSession) {
        val results = session.getFinalResults()
        
        // An√°lisis de participaci√≥n
        val remoteWords = results.filter { it.speakerLabel == "remote" }.sumOf { 
            it.text.split("\\s+".toRegex()).size 
        }
        val localWords = results.filter { it.speakerLabel == "local" }.sumOf { 
            it.text.split("\\s+".toRegex()).size 
        }
        
        val participationRatio = if (localWords > 0) {
            remoteWords.toFloat() / localWords.toFloat()
        } else {
            Float.MAX_VALUE
        }
        
        // An√°lisis de velocidad de habla
        val speechDuration = session.statistics.speechDuration / 1000f // en segundos
        val wordsPerMinute = if (speechDuration > 0) {
            (session.statistics.totalWords / speechDuration) * 60
        } else {
            0f
        }
        
        // An√°lisis de pausas
        val silenceRatio = session.statistics.silenceDuration.toFloat() / session.getDuration()
        
        Log.d("ConversationAnalysis", """
            An√°lisis de Conversaci√≥n:
            - Ratio de participaci√≥n: $participationRatio
            - Palabras por minuto: $wordsPerMinute
            - Ratio de silencio: ${(silenceRatio * 100).toInt()}%
            - Palabras remotas: $remoteWords
            - Palabras locales: $localWords
        """.trimIndent())
    }
}
```

## üîí Privacidad y Seguridad

### Configuraci√≥n de Privacidad

```kotlin
class TranscriptionPrivacyManager {
    
    fun setupPrivacyControls() {
        // Configuraci√≥n con filtros de privacidad
        val privacyConfig = AudioTranscriptionService.TranscriptionConfig(
            isEnabled = true,
            enableProfanityFilter = true, // Filtrar contenido inapropiado
            confidenceThreshold = 0.8f, // Solo alta confianza para datos sensibles
            // No guardar resultados parciales para mayor privacidad
            enablePartialResults = false
        )
        
        sipLibrary.enableAudioTranscription(privacyConfig)
    }
    
    fun enableLocalOnlyMode() {
        // Usar solo Android Speech (sin servicios en la nube)
        val localConfig = AudioTranscriptionService.TranscriptionConfig(
            transcriptionProvider = AudioTranscriptionService.TranscriptionProvider.ANDROID_SPEECH,
            isEnabled = true
        )
        
        sipLibrary.enableAudioTranscription(localConfig)
    }
    
    fun clearSensitiveData() {
        // Limpiar historial de transcripciones
        sipLibrary.clearTranscriptionHistory()
        
        // Limpiar datos de la base de datos
        lifecycleScope.launch {
            databaseManager.cleanupOldData(daysToKeep = 0) // Eliminar todo
        }
    }
}
```

## üéØ Conclusi√≥n

La integraci√≥n de transcripci√≥n de audio en tiempo real en EddysSipLibrary proporciona:

- ‚úÖ **Interceptaci√≥n directa** del audio WebRTC antes del altavoz
- ‚úÖ **Transcripci√≥n en tiempo real** con m√∫ltiples proveedores
- ‚úÖ **An√°lisis de calidad** de audio autom√°tico
- ‚úÖ **Persistencia completa** en base de datos
- ‚úÖ **Exportaci√≥n flexible** en m√∫ltiples formatos
- ‚úÖ **Configuraci√≥n granular** para diferentes casos de uso
- ‚úÖ **Privacidad y seguridad** con opciones locales

Esta implementaci√≥n te permite crear aplicaciones SIP con capacidades avanzadas de transcripci√≥n, an√°lisis de conversaciones y documentaci√≥n autom√°tica de llamadas.

---

**Desarrollado con ‚ù§Ô∏è por Eddys Larez**

*¬øTe gusta la nueva funcionalidad de transcripci√≥n? ¬°Dale una ‚≠ê en GitHub!*